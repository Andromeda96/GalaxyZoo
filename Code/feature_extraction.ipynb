{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sift feature extraction. <br>\n",
    "_<Strong>In:</Strong> cropped grayscale images_ <br>\n",
    "_<Strong>Out:</Strong> descriptor dataframe file(../sift_features.csv)_ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "img_path = '../images_training_processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_image(image_path):\n",
    "    image = Image.open(image_path)  # read as pil\n",
    "    \n",
    "    # Contrast\n",
    "    enh_con = ImageEnhance.Contrast(image)\n",
    "    contrast = 2.5\n",
    "    img_c = enh_con.enhance(contrast)\n",
    "\n",
    "\n",
    "    # Sharpness (not using)\n",
    "    enh_sha = ImageEnhance.Sharpness(img_c)\n",
    "    sharpness = 0.0 \n",
    "    img_cs = enh_sha.enhance(sharpness)\n",
    "\n",
    "    img_cs = cv2.cvtColor(np.asarray(img_cs), cv2.COLOR_GRAY2RGB)  # Convert from PIL to opencv in grayscale\n",
    "    \n",
    "    return img_cs  # cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_point_index(kp):\n",
    "#     dis = []  # normalized distance to center\n",
    "#     sizes = []  # normalized size of points\n",
    "\n",
    "#     for obj in kp:\n",
    "#         dis.append(math.sqrt((obj.pt[0]-103)**2 + (obj.pt[1]-103)**2))\n",
    "#         sizes.append(obj.size)\n",
    "        \n",
    "#     dis = np.array(dis) / max(dis)\n",
    "#     sizes = np.array(sizes) / max(sizes)\n",
    "#     scores = -0.5*dis + 0.5*sizes # score = -0.5*dis+0.5*size\n",
    "#     index = scores.tolist().index(np.max(scores))\n",
    "#     return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61579/61579 [12:14<00:00, 83.89it/s]\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "df = pd.DataFrame(columns=['Img_ID', 'Descriptor'])\n",
    "for img_name in tqdm(os.listdir(img_path)):\n",
    "    img_id = img_name[:-4]\n",
    "    if img_name.startswith('.'):  # exclude MacOS system file\n",
    "        continue\n",
    "    img = aug_image(img_path + img_name)\n",
    "    if img is None:\n",
    "        print('img ', img_id, ' is none!')\n",
    "        break\n",
    "    [kp, des] = sift.detectAndCompute(img, None)\n",
    "    df = df.append({'Img_ID': img_id, 'Descriptor': des}, ignore_index=True)\n",
    "        \n",
    "df.to_csv('../sift_features.csv')\n",
    "\n",
    "# Draw sift feature\n",
    "#     img=cv2.drawKeypoints(img,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "#     plt.imshow(img, cmap='gray')  # show sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
